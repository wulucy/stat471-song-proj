data2.validation <- data2.test[sample.validation,]
data2.test <- data2.test[-sample.validation,]
names(data2.train)[1:10]
dim(data2.train)
dim(data2.test)
dim(data2.validation)
Y <- data2.train$rating
X <- as.matrix(data2.train[, -c(1)]) # we can use as.matrix directly here
load("TextMining.RData")
plot(result.lasso)
lasso.lambda.1se <- result.lasso$lambda.1se
lasso.lambda.1se
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.1se")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial(logit))
result.glm.coef <- coef(result.glm)
# Pulling out the positive coefficients
good.glm <- result.glm.coef[which(result.glm.coef > 0)]
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.1se")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial(logit))
result.glm <- glm(glm.input, data=data2.train, family=binomial(logit))
# Combining into a new data frame
data1.temp <- data.frame(data.sample, as.matrix(dtm.clean))
data2 <- data1.temp[, c(11, 14:ncol(data1.temp))]
data2.train <- data2[sample.train,]
result.glm <- glm(glm.input, data=data2.train, family=binomial(logit))
result.glm <- glm(glm.input, data=data2.train, family=binomial())
result.glm.coef <- coef(result.glm)
result.glm <- glm(glm.input, data=data2.train, family=binomial())
result.glm <- glm(glm.input, data=data2.train, family=binomial())
result.glm.coef <- coef(result.glm)
# Pulling out the positive coefficients
good.glm <- result.glm.coef[which(result.glm.coef > 0)]
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial())
result.glm <- glm(glm.input, data=data2.train, family=binomial())
result.glm <- glm(glm.input, data=data2.train, family=binomia
result.glm <- glm(glm.input, data=data2.train, family=binomia)
result.glm <- glm(glm.input, data=data2.train, family=binomia;)
result.glm <- glm(glm.input, data=data2.train, family=binomial)
result.glm <- glm(glm.input, data=data2.train, family=binomial)
knitr::opts_chunk$set(fig.height=4, fig.width=6, warning = F)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(randomForest, tree, ISLR, rpart, rattle, pROC, partykit, ggplot2, glmnet, leaps, dplyr)
# constants for homework assignments
hw_num <- 4
hw_due_date <- "21, April, 2019"
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial)
names(data2)
sample.train <- sample(nrow(data2), 13000)
data2.train <- data2[sample.train,]
data2.test <- data2[-sample.train,]
sample.validation <- sample(nrow(data2.test), 2000)
data2.validation <- data2.test[sample.validation,]
data2.test <- data2.test[-sample.validation,]
names(data2.train)[1:10]
dim(data2.train)
dim(data2.test)
dim(data2.validation)
# Create rating
data.sample$rating <- c(0)
data.sample$rating[data.sample$stars >= 4] <- 1
data.sample$rating <- as.factor(data.sample$rating)
# Combining into a new data frame
data1.temp <- data.frame(data.sample, as.matrix(dtm.clean))
data2 <- data1.temp[, c(11, 14:ncol(data1.temp))]
names(data1.temp)
data2 <- data1.temp[, c(1, 7, 8, 11, 14:ncol(data1.temp))]
dim(data2)
names(data2)
names(data2)[1:10]
sample.train <- sample(nrow(data2), 13000)
data2.train <- data2[sample.train, -c(1:3)]
data2.test <- data2[-sample.train, -c(1:3)]
data2.test <- data2[-sample.train, -c(1:3)]
sample.validation <- sample(nrow(data2.test), 2000)
sample.validation <- sample(nrow(data2.test), 2000)
data2.validation <- data2.test[sample.validation,]
data2.test <- data2.test[-sample.validation,]
names(data2.train)[1:10]
dim(data2.test)
dim(data2.validation)
names(data2.train)
Y <- data2.train$rating
X <- as.matrix(data2.train[, -c(1)]) # we can use as.matrix directly here
result.lasso <- cv.glmnet(X, Y, alpha=.99, family="binomial")
X <- as.matrix(data2.train[, -c(1)]) # we can use as.matrix directly here
result.lasso <- cv.glmnet(X, Y, alpha=.99, family="binomial")
X
y
dim(data2.train)
result.lasso <- cv.glmnet(X, Y, alpha=.99, family="binomial")
names(data2.train)
names(data2.test)[1:10]
names(data2.validation)[1:10]
names(data2.train)[1:10]
names(data2.test)[1:10]
names(data2.validation)[1:10]
sample.train <- sample(nrow(data2), 13000)
data2.train <- data2[sample.train, -c(1:3)]
data2.test <- data2[-sample.train, -c(1:3)]
sample.validation <- sample(nrow(data2.test), 2000)
data2.validation <- data2.test[sample.validation,]
data2.test <- data2.test[-sample.validation,]
Y <- data2.train$rating
X <- as.matrix(data2.train[, -c(1)]) # we can use as.matrix directly here
X
result.lasso <- cv.glmnet(X, Y, alpha=.99, family="binomial")
dim(x)
dim(X)
dim(Y)
length(Y)
load("TextMining.RData")
plot(result.lasso)
sample.train <- sample(nrow(data2), 13000)
data2.train <- data2[sample.train, -c(1:3)]
Y <- data2.train$rating
data2.train[1,]
result.lasso <- cv.glmnet(X, Y, alpha=1, family="binomial")
# Load packages
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(tm)
library(data.table)
set.seed(1)
data.all <- fread("yelp_subset.csv", stringsAsFactors = FALSE)
dim(data.all)
sample.index <- sample(nrow(data.all), 20000)
data.sample <- data.all[sample.index,]
dim(data.sample)
text.sample <- data.sample$text
corpus1 <- VCorpus(VectorSource(text.sample))
corpus2 <- tm_map(corpus1, content_transformer(tolower)) # lowercase
corpus3 <- tm_map(corpus2, removeWords, stopwords("english")) # remove non-content words
corpus4 <- tm_map(corpus3, removePunctuation) # remove punctuations
corpus5 <- tm_map(corpus4, removeNumbers) # remove numbers
corpus6 <- tm_map(corpus5, stemDocument, lazy = TRUE) # words stem
dtm <- DocumentTermMatrix(corpus6)
dtm <- DocumentTermMatrix(corpus6)
threshold <- 0.05 * length(corpus6)
threshold.words <- findFreqTerms(dtm, lowfreq=threshold)
length(threshold.words)
dtm.clean <- DocumentTermMatrix(corpus6, control = list(dictionary = threshold.words))
dim(as.matrix(dtm.clean))
dtm.clean
# Create rating
data.sample$rating <- c(0)
data.sample$rating[data.sample$stars >= 4] <- 1
data.sample$rating <- as.factor(data.sample$rating)
# Combining into a new data frame
data1.temp <- data.frame(data.sample, as.matrix(dtm.clean))
data2 <- data1.temp[, c(1, 7, 8, 11, 14:ncol(data1.temp))]
dim(data2)
names(data2)[1:10]
sample.train <- sample(nrow(data2), 13000)
data2.train <- data2[sample.train, -c(1:3)]
data2.test <- data2[-sample.train, -c(1:3)]
sample.validation <- sample(nrow(data2.test), 2000)
data2.validation <- data2.test[sample.validation,]
data2.test <- data2.test[-sample.validation,]
Y <- data2.train$rating
X <- as.matrix(data2.train[, -c(1)])
result.lasso <- cv.glmnet(X, Y, alpha=1, family="binomial")
plot(result.lasso)
lasso.lambda.1se <- result.lasso$lambda.1se
lasso.lambda.1se
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.1se")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial)
result.glm <- glm(glm.input, data=data2.train, family=binomial)
result.glm.coef <- coef(result.glm)
# Pulling out the positive coefficients
good.glm <- result.glm.coef[which(result.glm.coef > 0)]
good.glm <- good.glm[-1]
good.glm <- sort(good.glm, decreasing=TRUE)
good.glm[1:2] # top two words
# Word cloud positive
cor.special <- brewer.pal(8,"Dark2")
good.word <- names(good.glm)
wordcloud(good.word[1:length(good.glm)], good.glm[1:length(good.glm)],colors=cor.special, ordered.colors=F) # there are only 67 good words
bad.glm <- result.glm.coef[which(result.glm.coef < 0)]
bad.glm <- bad.glm[-1]
bad.glm <- sort(-bad.glm, decreasing = TRUE)
bad.word <- names(bad.glm)
cor.special <- brewer.pal(6,"Dark2")
wordcloud(bad.word[1:length(bad.glm)], bad.glm[1:length(bad.glm)], color=cor.special, ordered.colors=F)
knitr::opts_chunk$set(fig.height=4, fig.width=6, warning = F)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(randomForest, tree, ISLR, rpart, rattle, pROC, partykit, ggplot2, glmnet, leaps, dplyr)
# constants for homework assignments
hw_num <- 4
hw_due_date <- "21, April, 2019"
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.min")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial)
min
min
min
min
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.min")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial)
# Error from glm fit
predict.glm <- predict(result.glm, data2.test[,-1], type = "response")
class.glm <- rep("0", 10000)
class.glm[predict.glm > .5] ="1"
mean(data2.test$rating != class.glm)
# Pulling out the betas
beta.lasso <- coef(result.lasso, s="lambda.1se")
beta <- beta.lasso[which(beta.lasso !=0),]
beta <- as.matrix(beta)
beta <- rownames(beta)
# Fitting into glm
glm.input <- as.formula(paste("rating", "~", paste(beta[-1],collapse = "+")))
result.glm <- glm(glm.input, data=data2.train, family=binomial)
# Error from glm fit
predict.glm <- predict(result.glm, data2.test[,-1], type = "response")
class.glm <- rep("0", 10000)
class.glm[predict.glm > .5] ="1"
mean(data2.test$rating != class.glm)
beta
# Error from LASSO fit
predict.lasso <- predict(result.lasso, as.matrix(data2.test[, -1]), type = "class", s="lambda.1se")
mean(data2.test$rating != predict.lasso)
# Error from glm fit
predict.glm <- predict(result.glm, data2.test[,-1], type = "response")
class.glm <- rep("0", 10000)
class.glm[predict.glm > .5] ="1"
mean(data2.test$rating != class.glm)
result.lasso
result.lasso$glmnet.fit
predict.val <- predict(result.lasso, as.matrix(data2.validation[, -1]), type = "class", s="lambda.1se")
mean(data2.test$rating != predict.lasso)
predict.val <- predict(result.lasso, as.matrix(data2.validation[, -1]), type = "class", s="lambda.1se")
mean(data2.validation$rating != predict.lasso)
mean(data2.validation$rating != predict.val)
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
library(keras)
install_keras()
install.packages(devtools)
install.packages("devtools")
devtools::install_github("rstudio/keras")
library(keras)
install_keras()
install_keras()
library(keras)
install_keras()
library(RSQLite)
filename <- "billboard-200.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db,"acoustic_features")
tables
acoustic.tb <- dbReadTable(db,"acoustic_features")
db <- dbConnect(sqlite.driver,
dbname = filename)
merge.new <- merge(bill100, acoustic.tb, by=c("artist", "song"))
bill100 <- read.csv(file = "Hot Stuff.csv")
bill100 <- read.csv(file = "Hot Stuff.csv")
library(RSQLite)
filename <- "billboard-200.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db, "acoustic_features")
albums.tb <- dbReadTable(db, "albums")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db, "acoustic_features")
db <- dbConnect(sqlite.driver,
dbname = filename)
library(RSQLite)
filename <- "billboard-200.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db, "acoustic_features")
getwd()
setwd("/Users/ndduong/Desktop/stat471-song-proj")
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db, "acoustic_features")
albums.tb <- dbReadTable(db, "albums")
# Reading data
bill100 <- read.csv(file = "Hot Stuff.csv")
colnames(bill100)[4] <- "song"
colnames(bill100)[5] <- "artist"
# Merging with World Data
merged.tb <- merge(bill100, acoustic.tb, by=c("artist", "song"))
merged.tb <- merged.tb[, -c(3, 5, 6, 7, 8, 11, 26, 27)]
merged.tb$WeekID <- as.Date(merged.tb$WeekID, "%m/%d/%Y")
names(merged.tb)
# Grouping
merged.tb2 <- merged.tb %>%
group_by(
song,
artist,
album,
acousticness,
danceability,
duration_ms,
energy,
instrumentalness,
key,
liveness,
loudness,
mode,
speechiness,
tempo,
time_signature,
valence) %>%
summarise(
WeekID = min(WeekID),
Peak.Position = max(Peak.Position),
Weeks.on.Chart = max(Weeks.on.Chart)
)
library(RSQLite)
filename <- "billboard-200.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
dbname = filename)
## Some operations
tables <- dbListTables(db)
acoustic.tb <- dbReadTable(db, "acoustic_features")
albums.tb <- dbReadTable(db, "albums")
# Reading data
bill100 <- read.csv(file = "Hot Stuff.csv")
colnames(bill100)[4] <- "song"
colnames(bill100)[5] <- "artist"
# Merging with World Data
merged.tb <- merge(bill100, acoustic.tb, by=c("artist", "song"))
merged.tb <- merged.tb[, -c(3, 5, 6, 7, 8, 11, 26, 27)]
merged.tb$WeekID <- as.Date(merged.tb$WeekID, "%m/%d/%Y")
names(merged.tb)
# Grouping
merged.tb2 <- merged.tb %>%
group_by(
song,
artist,
album,
acousticness,
danceability,
duration_ms,
energy,
instrumentalness,
key,
liveness,
loudness,
mode,
speechiness,
tempo,
time_signature,
valence) %>%
summarise(
WeekID = min(WeekID),
Peak.Position = max(Peak.Position),
Weeks.on.Chart = max(Weeks.on.Chart)
)
library(dplyr)
# Grouping
merged.tb2 <- merged.tb %>%
group_by(
song,
artist,
album,
acousticness,
danceability,
duration_ms,
energy,
instrumentalness,
key,
liveness,
loudness,
mode,
speechiness,
tempo,
time_signature,
valence) %>%
summarise(
WeekID = min(WeekID),
Peak.Position = max(Peak.Position),
Weeks.on.Chart = max(Weeks.on.Chart)
)
# Subset of songs after 2000
df2000 <- as.data.frame(subset(merged.tb2, format(WeekID,"%Y")>=2000))
df2000 <- df2000[order(df2000$WeekID), ]
dim(df2000)
df2000_grouped <- df2000 %>%
group_by(song, artist, WeekID, Peak.Position, Weeks.on.Chart) %>%
summarise(
acousticness = round(mean(acousticness), 3),
danceability = round(mean(danceability), 3),
duration_ms = as.integer(mean(duration_ms)),
energy = round(mean(energy), 3),
instrumentalness = mean(instrumentalness),
key = as.integer(mean(key)),
liveness = round(mean(liveness), 3),
loudness = round(mean(loudness), 3),
mode = as.integer(mean(mode)),
speechiness = round(mean(speechiness), 4),
tempo = round(mean(tempo), 3),
time_signature = as.integer(mean(time_signature)),
valence = round(mean(valence), 3)
)
df2000_grouped = as.data.frame(df2000_grouped)
# Add factors
# Create season factor
# Winter = 12, 1, 2; Spring = 3, 4, 5, Summer = 6,7,8 Fall = 9, 10, 11
df2000.seasons <- df2000_grouped %>%
mutate(Month=as.numeric(format(WeekID, "%m"))) %>%
mutate(Season=
case_when(
Month == 12 | Month <= 2 ~ "Winter",
Month >= 3 & Month <= 5 ~ "Spring",
Month >= 6 & Month <= 8 ~ "Summer",
Month >= 9 & Month <= 11 ~ "Fall",
TRUE ~ "NA"
)
)
# Create artist popularity factor
# artist.pop = number of hot 100 songs by artist in past 3 years
library(lubridate)
# Create artist popularity factor
# artist.pop = number of hot 100 songs by artist in past 3 years
df1997 <- as.data.frame(subset(merged.tb2, format(WeekID,"%Y")>=1997))
df1997 <- df1997[order(df1997$WeekID), ] # get songs since 1997
artist.pop.list <- c()
for (idx in 1:nrow(df2000)) {
WeekID <- df2000[idx, "WeekID"]
artist <- df2000[idx, "artist"]
three.y.earlier <- WeekID %m-% months(12*3)
artist.pop <- nrow(df1997[(df1997$artist == artist) & (df1997$WeekID < WeekID) & (df1997$WeekID >= three.y.earlier),])
artist.pop.list <- c(artist.pop.list, artist.pop)
}
df2000.seasons$artist.pop <- artist.pop.list
for (idx in 1:nrow(df2000_grouped)) {
WeekID <- df2000[idx, "WeekID"]
artist <- df2000[idx, "artist"]
three.y.earlier <- WeekID %m-% months(12*3)
artist.pop <- nrow(df1997[(df1997$artist == artist) & (df1997$WeekID < WeekID) & (df1997$WeekID >= three.y.earlier),])
artist.pop.list <- c(artist.pop.list, artist.pop)
}
for (idx in 1:nrow(df2000_grouped)) {
WeekID <- df2000_grouped[idx, "WeekID"]
artist <- df2000_grouped[idx, "artist"]
three.y.earlier <- WeekID %m-% months(12*3)
artist.pop <- nrow(df1997[(df1997$artist == artist) & (df1997$WeekID < WeekID) & (df1997$WeekID >= three.y.earlier),])
artist.pop.list <- c(artist.pop.list, artist.pop)
}
artist.pop.list <- c()
for (idx in 1:nrow(df2000_grouped)) {
WeekID <- df2000_grouped[idx, "WeekID"]
artist <- df2000_grouped[idx, "artist"]
three.y.earlier <- WeekID %m-% months(12*3)
artist.pop <- nrow(df1997[(df1997$artist == artist) & (df1997$WeekID < WeekID) & (df1997$WeekID >= three.y.earlier),])
artist.pop.list <- c(artist.pop.list, artist.pop)
}
df2000.seasons$artist.pop <- artist.pop.list
write.csv(df2000.seasons, 'df2000_grouped_morefactors.csv')
df2000.seasons
df2000.seasons
df2000.seasons[df2000.seasons$Peak.Position <= 10]
df2000.seasons[df2000.seasons$Peak.Position <= 10]
df2000.seasons[df2000.seasons$Peak.Position <= 10,]
dim(df2000.seasons[df2000.seasons$Peak.Position <= 10,])
dim(df2000.seasons[df2000.seasons$Peak.Position <= 50,])
dim(df2000.seasons[df2000.seasons$Peak.Position >0,])
dim(df2000.seasons[df2000.seasons$Peak.Position <= 90,])
